{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consider description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# library\n",
    "# ==================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../datasets/'\n",
    "out_dir = '../output/'\n",
    "TRAIN_PATH = data+\"train.csv\"\n",
    "TEST_PATH = data+ 'test.csv'\n",
    "SUB_PATH = data + 'atmacup10__sample_submission.csv'\n",
    "SAVE_TEST_SUB_PATH = out_dir + \"sub.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Settings\n",
    "# ===============\n",
    "\n",
    "SEED = 0\n",
    "N_SPLITS = 5\n",
    "SHUFFLE = True\n",
    "LGBM_PARAMS = {'num_leaves': 32,\n",
    "               'min_data_in_leaf': 64,\n",
    "               'objective': 'regression',\n",
    "               'max_depth': -1,\n",
    "               'learning_rate': 0.05,\n",
    "               \"boosting\": \"gbdt\",\n",
    "               \"bagging_freq\": 1,\n",
    "               \"bagging_fraction\": 0.8,\n",
    "               \"bagging_seed\": SEED,\n",
    "               \"verbosity\": -1,\n",
    "              'reg_alpha': 0.1,\n",
    "              'reg_lambda': 0.3,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'metric':\"rmse\",\n",
    "              'num_threads':6,\n",
    "         }\n",
    "\n",
    "LGBM_FIT_PARAMS = {\n",
    "    'num_boost_round': 10000,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'verbose_eval': 200,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Function\n",
    "# =====================\n",
    "def train_lgbm(X_train, y_train, X_valid, y_valid, X_test, categorical_features, feature_name, fold_id,lgb_params, fit_params, loss_func, calc_importances=True):\n",
    "    \n",
    "    train_df = lgb.Dataset(X_train, y_train,\n",
    "                        categorical_feature=categorical_features,\n",
    "                        feature_name=feature_name)\n",
    "    if X_valid is not None:\n",
    "        valid = lgb.Dataset(X_valid, y_valid,\n",
    "                            categorical_feature=categorical_features,\n",
    "                            feature_name=feature_name)\n",
    "   \n",
    "    if X_valid is not None:\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_df,\n",
    "            valid_sets=[train_df,valid],\n",
    "            **fit_params\n",
    "        )\n",
    "    else:\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_df,\n",
    "            **fit_params\n",
    "        )\n",
    "    \n",
    "    # train score\n",
    "    if X_valid is not None:\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        valid_loss = loss_func(y_valid, y_pred_valid)\n",
    "    else:\n",
    "        y_pred_valid = None\n",
    "        valid_loss = None\n",
    "    \n",
    "    #test\n",
    "    if X_test is not None:\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred_test = None\n",
    "\n",
    "    if calc_importances:\n",
    "        importances = pd.DataFrame()\n",
    "        importances['feature'] = feature_name\n",
    "        importances['gain'] = model.feature_importance(importance_type='gain')\n",
    "        importances['split'] = model.feature_importance(importance_type='split')\n",
    "        importances['fold'] = fold_id\n",
    "    else:\n",
    "        importances = None\n",
    "\n",
    "    return y_pred_valid, y_pred_test, valid_loss, importances, model.best_iteration\n",
    "\n",
    "def calc_loss(y_true, y_pred):\n",
    "    return  np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def get_dim(df):\n",
    "    df['dim'] = ''\n",
    "#     df[df['sub_title'].isnull()] = '0'\n",
    "    df['dim'] = df['sub_title'].str.count('×')\n",
    "#     for i in range(len(df)):\n",
    "#         df['dim'][i] = df['sub_title'][i].count('×')+1\n",
    "#     df['dim'] = df['dim'].astype(int)\n",
    "    return df\n",
    "def get_collection(df, collections):\n",
    "    obj_collection_df = pd.read_csv('../datasets/object_collection.csv')\n",
    "    df ['has_collection'] = df['object_id'].isin(obj_collection_df['object_id'])*1\n",
    "    for collect in collections:\n",
    "        print(collect)\n",
    "        df['has_'+collect] = ''\n",
    "        df['has_'+collect] = df['object_id'].isin(obj_collection_df['object_id'][obj_collection_df['name'] == collect])*1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "len_train = len(train_df)\n",
    "y = np.log1p(train_df[\"likes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['description'] = train_df['description'].isnull()*1\n",
    "test_df['description'] = test_df['description'].isnull()*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paintings\n",
      "prints\n",
      "paintings\n",
      "prints\n"
     ]
    }
   ],
   "source": [
    "collections = ['paintings','prints']\n",
    "train_df = get_collection(train_df,collections)\n",
    "test_df = get_collection(test_df,collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = get_dim(train_df)\n",
    "test_df = get_dim(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['principal_maker', 'principal_or_first_maker',\n",
    "        'copyright_holder','acquisition_method',\n",
    "       'acquisition_credit_line', \n",
    "       'dating_period', 'dating_year_early',\n",
    "       'dating_year_late','description','has_prints',\n",
    "        'has_paintings',\n",
    "        'has_collection',\n",
    "        'dim',\n",
    "       ]\n",
    "cat_cols = ['principal_maker', 'principal_or_first_maker','copyright_holder','acquisition_method','acquisition_credit_line','dim',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df.loc[~train_df[c].isin(test_df[c].unique()),c] = np.nan\n",
    "    test_df.loc[~test_df[c].isin(train_df[c].unique()),c] = np.nan\n",
    "train_df = pd.concat([train_df[cols],test_df[cols]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    train_df[c] = le.fit_transform(train_df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df.iloc[len_train:].reset_index(drop=True)\n",
    "train_df = train_df.iloc[:len_train].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 1.01132\tvalid_1's rmse: 1.10073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 0.970166\tvalid_1's rmse: 1.10046\n",
      "Early stopping, best iteration is:\n",
      "[298]\ttraining's rmse: 0.98831\tvalid_1's rmse: 1.09892\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.01877\tvalid_1's rmse: 1.07864\n",
      "[400]\ttraining's rmse: 0.977259\tvalid_1's rmse: 1.07542\n",
      "[600]\ttraining's rmse: 0.949687\tvalid_1's rmse: 1.07419\n",
      "Early stopping, best iteration is:\n",
      "[577]\ttraining's rmse: 0.952346\tvalid_1's rmse: 1.07347\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 1.00448\tvalid_1's rmse: 1.12901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 0.96301\tvalid_1's rmse: 1.12758\n",
      "Early stopping, best iteration is:\n",
      "[294]\ttraining's rmse: 0.982228\tvalid_1's rmse: 1.12713\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.01888\tvalid_1's rmse: 1.08721\n",
      "[400]\ttraining's rmse: 0.977678\tvalid_1's rmse: 1.08221\n",
      "Early stopping, best iteration is:\n",
      "[367]\ttraining's rmse: 0.982922\tvalid_1's rmse: 1.0812\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.01608\tvalid_1's rmse: 1.07644\n",
      "[400]\ttraining's rmse: 0.97456\tvalid_1's rmse: 1.07583\n",
      "[600]\ttraining's rmse: 0.947217\tvalid_1's rmse: 1.07657\n",
      "Early stopping, best iteration is:\n",
      "[475]\ttraining's rmse: 0.963411\tvalid_1's rmse: 1.07395\n",
      "1.0911230486742547\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=N_SPLITS,random_state=SEED, shuffle=SHUFFLE)\n",
    "y_oof = np.empty([len(train_df),])\n",
    "y_test = []\n",
    "features = list(train_df.columns)\n",
    "drop_cols = []\n",
    "features = [i for i in features if i not in drop_cols]\n",
    "feature_importances = pd.DataFrame()\n",
    "categorical_features = [\"principal_maker\",\"principal_or_first_maker\"]\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(train_df,y)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    x_train, y_train = train_df.iloc[train_idx][features], y.iloc[train_idx]\n",
    "    x_val, y_val =train_df.iloc[valid_idx][features], y.iloc[valid_idx]\n",
    "\n",
    "    y_pred_valid, y_pred_test, valid_loss, importances, best_iter = train_lgbm(\n",
    "                x_train, y_train, x_val, y_val,test_df[features],\n",
    "                categorical_features=categorical_features,\n",
    "                feature_name=features,\n",
    "                fold_id=fold,\n",
    "                lgb_params=LGBM_PARAMS,\n",
    "                fit_params=LGBM_FIT_PARAMS,\n",
    "                loss_func=calc_loss,\n",
    "                calc_importances=True\n",
    "            )\n",
    "\n",
    "    y_oof[valid_idx] = y_pred_valid\n",
    "    score = calc_loss(y[valid_idx], y_pred_valid)\n",
    "    y_test.append(y_pred_test)\n",
    "    feature_importances = pd.concat([feature_importances, importances], axis=0, sort=True)\n",
    "\n",
    "score = calc_loss(y, y_oof)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sub =  np.mean(y_test,axis=0)\n",
    "y_test_sub = np.expm1(y_test_sub)\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "sub[\"likes\"] = y_test_sub\n",
    "sub.loc[sub.likes <= 0,\"likes\"] = 0\n",
    "sub.to_csv(SAVE_TEST_SUB_PATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>fold</th>\n",
       "      <th>gain</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>principal_maker</td>\n",
       "      <td>0</td>\n",
       "      <td>17267.606146</td>\n",
       "      <td>938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>principal_or_first_maker</td>\n",
       "      <td>0</td>\n",
       "      <td>7111.090234</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>copyright_holder</td>\n",
       "      <td>0</td>\n",
       "      <td>287.958796</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acquisition_method</td>\n",
       "      <td>0</td>\n",
       "      <td>7570.999868</td>\n",
       "      <td>684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>acquisition_credit_line</td>\n",
       "      <td>0</td>\n",
       "      <td>6046.706195</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>description</td>\n",
       "      <td>4</td>\n",
       "      <td>1040.597956</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>has_prints</td>\n",
       "      <td>4</td>\n",
       "      <td>22694.096225</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>has_paintings</td>\n",
       "      <td>4</td>\n",
       "      <td>68538.721419</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>has_collection</td>\n",
       "      <td>4</td>\n",
       "      <td>7175.760677</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dim</td>\n",
       "      <td>4</td>\n",
       "      <td>16311.231321</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature  fold          gain  split\n",
       "0            principal_maker     0  17267.606146    938\n",
       "1   principal_or_first_maker     0   7111.090234    566\n",
       "2           copyright_holder     0    287.958796     54\n",
       "3         acquisition_method     0   7570.999868    684\n",
       "4    acquisition_credit_line     0   6046.706195   1062\n",
       "..                       ...   ...           ...    ...\n",
       "8                description     4   1040.597956    245\n",
       "9                 has_prints     4  22694.096225    158\n",
       "10             has_paintings     4  68538.721419    211\n",
       "11            has_collection     4   7175.760677     73\n",
       "12                       dim     4  16311.231321    310\n",
       "\n",
       "[65 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "pyvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
