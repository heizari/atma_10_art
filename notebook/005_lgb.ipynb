{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consider object_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================\n",
    "# library\n",
    "# ==================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../datasets/'\n",
    "out_dir = '../output/'\n",
    "TRAIN_PATH = data+\"train.csv\"\n",
    "TEST_PATH = data+ 'test.csv'\n",
    "SUB_PATH = data + 'atmacup10__sample_submission.csv'\n",
    "SAVE_TEST_SUB_PATH = out_dir + \"sub.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============\n",
    "# Settings\n",
    "# ===============\n",
    "\n",
    "SEED = 0\n",
    "N_SPLITS = 5\n",
    "SHUFFLE = True\n",
    "LGBM_PARAMS = {'num_leaves': 32,\n",
    "               'min_data_in_leaf': 64,\n",
    "               'objective': 'regression',\n",
    "               'max_depth': -1,\n",
    "               'learning_rate': 0.05,\n",
    "               \"boosting\": \"gbdt\",\n",
    "               \"bagging_freq\": 1,\n",
    "               \"bagging_fraction\": 0.8,\n",
    "               \"bagging_seed\": SEED,\n",
    "               \"verbosity\": -1,\n",
    "              'reg_alpha': 0.1,\n",
    "              'reg_lambda': 0.3,\n",
    "              'colsample_bytree': 0.7,\n",
    "              'metric':\"rmse\",\n",
    "              'num_threads':6,\n",
    "         }\n",
    "\n",
    "LGBM_FIT_PARAMS = {\n",
    "    'num_boost_round': 10000,\n",
    "    'early_stopping_rounds': 200,\n",
    "    'verbose_eval': 200,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# Function\n",
    "# =====================\n",
    "def train_lgbm(X_train, y_train, X_valid, y_valid, X_test, categorical_features, feature_name, fold_id,lgb_params, fit_params, loss_func, calc_importances=True):\n",
    "    \n",
    "    train_df = lgb.Dataset(X_train, y_train,\n",
    "                        categorical_feature=categorical_features,\n",
    "                        feature_name=feature_name)\n",
    "    if X_valid is not None:\n",
    "        valid = lgb.Dataset(X_valid, y_valid,\n",
    "                            categorical_feature=categorical_features,\n",
    "                            feature_name=feature_name)\n",
    "   \n",
    "    if X_valid is not None:\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_df,\n",
    "            valid_sets=[train_df,valid],\n",
    "            **fit_params\n",
    "        )\n",
    "    else:\n",
    "        model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_df,\n",
    "            **fit_params\n",
    "        )\n",
    "    \n",
    "    # train score\n",
    "    if X_valid is not None:\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        valid_loss = loss_func(y_valid, y_pred_valid)\n",
    "    else:\n",
    "        y_pred_valid = None\n",
    "        valid_loss = None\n",
    "    \n",
    "    #test\n",
    "    if X_test is not None:\n",
    "        y_pred_test = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred_test = None\n",
    "\n",
    "    if calc_importances:\n",
    "        importances = pd.DataFrame()\n",
    "        importances['feature'] = feature_name\n",
    "        importances['gain'] = model.feature_importance(importance_type='gain')\n",
    "        importances['split'] = model.feature_importance(importance_type='split')\n",
    "        importances['fold'] = fold_id\n",
    "    else:\n",
    "        importances = None\n",
    "\n",
    "    return y_pred_valid, y_pred_test, valid_loss, importances, model.best_iteration\n",
    "\n",
    "def calc_loss(y_true, y_pred):\n",
    "    return  np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "def get_collection(df, collections):\n",
    "    obj_collection_df = pd.read_csv('../datasets/object_collection.csv')\n",
    "    df ['has_collection'] = df['object_id'].isin(obj_collection_df['object_id'])*1\n",
    "    for collect in collections:\n",
    "        print(collect)\n",
    "        df['has_'+collect] = ''\n",
    "        df['has_'+collect] = df['object_id'].isin(obj_collection_df['object_id'][obj_collection_df['name'] == collect])*1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "len_train = len(train_df)\n",
    "y = np.log1p(train_df[\"likes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['description'] = train_df['description'].isnull()*1\n",
    "test_df['description'] = test_df['description'].isnull()*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paintings\n",
      "prints\n",
      "paintings\n",
      "prints\n"
     ]
    }
   ],
   "source": [
    "collections = ['paintings','prints']\n",
    "train_df = get_collection(train_df,collections)\n",
    "test_df = get_collection(test_df,collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['principal_maker', 'principal_or_first_maker',\n",
    "        'copyright_holder','acquisition_method',\n",
    "       'acquisition_credit_line', \n",
    "       'dating_period', 'dating_year_early',\n",
    "       'dating_year_late','description','has_prints',\n",
    "        'has_paintings',\n",
    "        'has_collection',\n",
    "       ]\n",
    "cat_cols = ['principal_maker', 'principal_or_first_maker','copyright_holder','acquisition_method','acquisition_credit_line']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df.loc[~train_df[c].isin(test_df[c].unique()),c] = np.nan\n",
    "    test_df.loc[~test_df[c].isin(train_df[c].unique()),c] = np.nan\n",
    "train_df = pd.concat([train_df[cols],test_df[cols]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_cols:\n",
    "    train_df[c] = train_df[c].astype(str)\n",
    "    le = LabelEncoder()\n",
    "    train_df[c] = le.fit_transform(train_df[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = train_df.iloc[len_train:].reset_index(drop=True)\n",
    "train_df = train_df.iloc[:len_train].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.01674\tvalid_1's rmse: 1.10872\n",
      "[400]\ttraining's rmse: 0.97806\tvalid_1's rmse: 1.10928\n",
      "Early stopping, best iteration is:\n",
      "[275]\ttraining's rmse: 0.999658\tvalid_1's rmse: 1.10831\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.02368\tvalid_1's rmse: 1.08111\n",
      "[400]\ttraining's rmse: 0.985182\tvalid_1's rmse: 1.07619\n",
      "[600]\ttraining's rmse: 0.959583\tvalid_1's rmse: 1.07617\n",
      "Early stopping, best iteration is:\n",
      "[464]\ttraining's rmse: 0.975572\tvalid_1's rmse: 1.07543\n",
      "Fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 1.00816\tvalid_1's rmse: 1.13668\n",
      "[400]\ttraining's rmse: 0.970542\tvalid_1's rmse: 1.13422\n",
      "Early stopping, best iteration is:\n",
      "[341]\ttraining's rmse: 0.979807\tvalid_1's rmse: 1.13337\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttraining's rmse: 1.02254\tvalid_1's rmse: 1.08884\n",
      "[400]\ttraining's rmse: 0.985733\tvalid_1's rmse: 1.08207\n",
      "[600]\ttraining's rmse: 0.960648\tvalid_1's rmse: 1.08317\n",
      "Early stopping, best iteration is:\n",
      "[501]\ttraining's rmse: 0.971908\tvalid_1's rmse: 1.08107\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's rmse: 1.02202\tvalid_1's rmse: 1.08356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1551: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1286: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  warnings.warn('Overriding the parameters from Reference Dataset.')\n",
      "/home/wsato/work/pyvenv/lib/python3.8/site-packages/lightgbm/basic.py:1098: UserWarning: categorical_column in param dict is overridden.\n",
      "  warnings.warn('{} in param dict is overridden.'.format(cat_alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\ttraining's rmse: 0.98352\tvalid_1's rmse: 1.08233\n",
      "Early stopping, best iteration is:\n",
      "[286]\ttraining's rmse: 1.00272\tvalid_1's rmse: 1.08051\n",
      "1.0959608250524109\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=N_SPLITS,random_state=SEED, shuffle=SHUFFLE)\n",
    "y_oof = np.empty([len(train_df),])\n",
    "y_test = []\n",
    "features = list(train_df.columns)\n",
    "drop_cols = []\n",
    "features = [i for i in features if i not in drop_cols]\n",
    "feature_importances = pd.DataFrame()\n",
    "categorical_features = [\"principal_maker\",\"principal_or_first_maker\"]\n",
    "for fold, (train_idx, valid_idx) in enumerate(kf.split(train_df,y)):\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    x_train, y_train = train_df.iloc[train_idx][features], y.iloc[train_idx]\n",
    "    x_val, y_val =train_df.iloc[valid_idx][features], y.iloc[valid_idx]\n",
    "\n",
    "    y_pred_valid, y_pred_test, valid_loss, importances, best_iter = train_lgbm(\n",
    "                x_train, y_train, x_val, y_val,test_df[features],\n",
    "                categorical_features=categorical_features,\n",
    "                feature_name=features,\n",
    "                fold_id=fold,\n",
    "                lgb_params=LGBM_PARAMS,\n",
    "                fit_params=LGBM_FIT_PARAMS,\n",
    "                loss_func=calc_loss,\n",
    "                calc_importances=True\n",
    "            )\n",
    "\n",
    "    y_oof[valid_idx] = y_pred_valid\n",
    "    score = calc_loss(y[valid_idx], y_pred_valid)\n",
    "    y_test.append(y_pred_test)\n",
    "    feature_importances = pd.concat([feature_importances, importances], axis=0, sort=False)\n",
    "\n",
    "score = calc_loss(y, y_oof)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sub =  np.mean(y_test,axis=0)\n",
    "y_test_sub = np.expm1(y_test_sub)\n",
    "sub = pd.read_csv(SUB_PATH)\n",
    "sub[\"likes\"] = y_test_sub\n",
    "sub.loc[sub.likes <= 0,\"likes\"] = 0\n",
    "sub.to_csv(SAVE_TEST_SUB_PATH,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyvenv",
   "language": "python",
   "name": "pyvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
